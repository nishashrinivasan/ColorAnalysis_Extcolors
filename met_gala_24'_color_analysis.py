# -*- coding: utf-8 -*-
"""MET Gala 24' Color Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UHif9MaL9lWfKdCHkGz4owhWLgptyq9q

# **Color Analysis of Met Gala 2024 Outfits**

---

Color analysis of Met Gala fashion represents far more than a technical exercise—it captures a pivotal moment in the fashion ecosystem's evolution. The Met Gala, as fashion's most prestigious annual event, functions as both a cultural barometer and a launching pad for trends that ultimately influence everyday wardrobes worldwide. By quantitatively analyzing the color palettes dominating this event, we gain measurable insights into the initial stages of fashion's trickle-down effect.


The **"trickle-down theory"** in fashion, first formalized by sociologist Georg Simmel, describes how aesthetic choices from high fashion gradually permeate through society's various strata. The color analysis project provides empirical evidence of this phenomenon's starting point. When certain colors dominate the Met Gala:

1. Industry Adoption: Designers incorporate these colors into their ready-to-wear collections
2. Retail Translation: Luxury retailers adopt these palettes, followed by mid-tier brands
3. Mass Market Integration: Fast fashion brands and mainstream retailers incorporate diluted versions
4. Consumer Accessibility: Colors appear in shopping malls and online stores worldwide

What begins as a designer's bold choice on the Met Gala carpet transforms, within 8-18 months, into color options available at every price point.


This project was inspired by a compelling vexillology project that analyzed the color compositions of national flags using Python. That project utilized tools such as PIL and the extcolors library to extract dominant colors, presenting a visually engaging look at global design patterns. I came across extcolors through this work, which laid the groundwork for my own exploration into fashion and color at the Met Gala. I'm grateful to the original creator for making their repository public, which served as a helpful reference. For anyone interested in their project, it’s available at https://www.geodev.me/projects/flags-colors.
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required libraries
!pip install opencv-python-headless scikit-learn webcolors seaborn pandas colormath extcolors

# Import necessary libraries & modules for the analysis

import os #File path directory
import json # CSS3 colors dictionary
import numpy as np  # Numerical operations, arrays, linear algebra
import pandas as pd  # Data manipulation and analysis (DataFrames, CSV, etc.)
import matplotlib.pyplot as plt  # Plotting and data visualization
import seaborn as sns  # Statistical data visualization, built on matplotlib
from sklearn.cluster import KMeans  # K-Means clustering algorithm from scikit-learn
from collections import Counter  # Counting hashable objects (e.g., color frequencies)
import os  # Interacting with the operating system (e.g., file paths, directories)
import cv2  # OpenCV for image processing
from PIL import Image  # Image handling and manipulation from the Pillow library
import extcolors  # Extracting dominant colors from images
from matplotlib.ticker import MaxNLocator # MaxNLocator is used to force integer tick marks on axes (no decimals)

# Load CSS3 colors from the uploaded JSON file
json_file_path = '/content/css3_colors.json'  # Path to the uploaded JSON file

with open(json_file_path, 'r') as f:
    CSS3_COLORS = json.load(f)

# Configuration
IMAGE_FOLDER = "/content/drive/MyDrive/met_gala_2024"
N_COLORS = 3
OUTPUT_CSV = "/content/drive/MyDrive/met_gala_2024_color_data.csv"

"""**Preprocessing/Filtering Technique**

---


Since all the images have a consistent green carpet background, we minimize color noise by filtering out that specific green range so the code focuses only on the clothing and not the carpet.

The method is a color-based pixel filtering technique that removes a specific color range—here, the green carpet—from an image. It's a form of basic image masking using NumPy, and it works by identifying and modifying only those pixels that fall within a predefined color threshold.

1. Define Color Range:
The variables LOWER_GREEN and UPPER_GREEN represent the RGB boundaries of what is considered "green carpet."
2. Create a Boolean Mask:
For every pixel in the image, the code checks if the red, green, and blue components fall within the defined green range. The result is a 2D boolean mask where:
True = the pixel is part of the green carpet
False = it's not
3. Apply the Mask:
A copy of the image is made, and for all pixels where the mask is True, the pixel value is replaced with [0, 0, 0] (black). All other pixels are untouched.
"""

# Define the green carpet color range constants
# These values define the RGB boundaries for what's considered "green carpet"

LOWER_GREEN = (50, 100, 50)  # Lower bound RGB values for green carpet
UPPER_GREEN = (150, 220, 150)  # Upper bound RGB values for green carpet

# Function to filter out green carpet from images
# This function creates a mask for pixels that match the green carpet color
# range and sets them to black, reducing noise in our color analysis

def filter_green_carpet(image):
    """Filter out pixels that match the green carpet color range."""
    # Create a mask for pixels within the green carpet color range
    mask = (
        (image[:,:,0] >= LOWER_GREEN[0]) & (image[:,:,0] <= UPPER_GREEN[0]) &
        (image[:,:,1] >= LOWER_GREEN[1]) & (image[:,:,1] <= UPPER_GREEN[1]) &
        (image[:,:,2] >= LOWER_GREEN[2]) & (image[:,:,2] <= UPPER_GREEN[2])
    )
    """image is a 3D NumPy array with shape (height, width, 3) — representing an RGB image.
        image[:, :, 0] accesses the Red channel of all pixels.
        image[:, :, 1] accesses the Green channel.
        image[:, :, 2] accesses the Blue channel."""

    # Create a copy of the image and set masked pixels to black
    filtered = image.copy()
    filtered[mask] = [0, 0, 0]

    return filtered

def get_colors_with_extcolors(image_path, n_colors=N_COLORS):
    """Extract dominant colors from an image using the extcolors library,
    filtering out green carpet tones and ignoring small color fragments."""

    try:
        # Open the image and convert it to RGB mode to standardize color processing
        img = Image.open(image_path).convert("RGB")

        # Extract dominant colors using extcolors.
        # - `tolerance=12` groups similar colors together by merging those within 12 RGB units of each other.
        #   This helps avoid minor color variations (like shadows/highlights) from being treated as separate colors.
        # - `limit=n_colors` restricts the number of returned dominant colors.
        colors_result = extcolors.extract_from_image(img, tolerance=12, limit=n_colors)

        colors = []  # List to hold filtered dominant colors
        total_pixels = colors_result[1]  # Total number of pixels analyzed

        for color_data in colors_result[0]:
            color = color_data[0]  # RGB color tuple
            count = color_data[1]  # Number of pixels of this color

            # Check if the color falls within the green carpet range
            #This is a boolean mask using element-wise logical AND operations with NumPy arrays
            is_green_carpet = (
                LOWER_GREEN[0] <= color[0] <= UPPER_GREEN[0] and
                LOWER_GREEN[1] <= color[1] <= UPPER_GREEN[1] and
                LOWER_GREEN[2] <= color[2] <= UPPER_GREEN[2]
            )

            # Only keep colors that are:
            # - Not green carpet
            # - Make up more than 5% of total image pixels (to filter out small fragments)
            if not is_green_carpet and count / total_pixels > 0.05:
                colors.append((color, count))

        # Sort the colors by their count (most frequent first)
        colors.sort(key=lambda x: x[1], reverse=True)

        # Return just the RGB values (not the counts) in sorted order
        sorted_colors = [color[0] for color in colors]
        #Sorts the list of tuples in descending order of pixel count
        #The most dominant color appears first

        return sorted_colors

    except Exception as e:
        #Error handling prints the error and returns an empty list so script doesn’t crash
        print(f"Error processing image {image_path}: {e}")
        return []

"""**Role of Tolerance = 12**

---
When extcolors analyzes an image, it looks at each pixel's RGB value. If two pixels have similar colors — say (201, 33, 45) and (202, 34, 44) — a low tolerance might treat them as different colors, while a higher tolerance would group them together as the same dominant color.

RGB colors that differ by up to ±12 units per channel can be considered part of the same color group. This smooths out small lighting or compression differences.

1. Real-world photographs have shadows, gradients, and JPEG compression — they
introduce noise.
2. Without tolerance, the same dress might be recorded as 20 slightly different reds.
3. A tolerance of 12 reduces fragmentation, giving you fewer, clearer, more meaningful dominant colors.

If you set tolerance to 3: You’ll get more fragmented, precise colors.
If you set tolerance to 20: You’ll get smoother groupings, but less color precision.

**K-means**

---

In the get_colors_with_kmeans() function, KMeans clustering is used to extract dominant colors from an image by grouping similar pixels into clusters. The idea behind this approach is that KMeans helps in identifying the most prevalent colors in an image by grouping pixels that share similar color values (RGB). KMeans is suitable for this task because it can find clusters of colors, even if those colors appear in varying shades or slightly different tones.

The function starts by reading the image, converting it to RGB, and then filtering out the green carpet colors. After reshaping the image into a list of pixels, KMeans clustering is applied to group the colors. The number of clusters (n_colors) is set by the user, and this determines how many dominant colors will be returned.

After clustering, the function extracts the cluster centers (which represent the dominant colors) and their frequency. These are then sorted by their frequency and filtered to remove any near-black colors, which might be artifacts caused by the green carpet filter or noise. Finally, the function ensures that the number of returned colors is equal to n_colors, padding with black colors if necessary.

The reason KMeans is a good fit here is that it efficiently finds groups of similar colors in an image, even if those colors are not exact but close enough to be perceived as the same. It's especially useful when dealing with images with many subtle color variations.
"""

#Setting up for Kmeans

def get_colors_with_kmeans(image_path, n_colors=N_COLORS):
    """Extract dominant colors using KMeans clustering"""
    try:
        # Read image with OpenCV
        image = cv2.imread(image_path)
        if image is None:
            return [(0, 0, 0)] * n_colors

        # Convert to RGB (OpenCV uses BGR)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Filter out green carpet
        filtered_image = filter_green_carpet(image)

        # Reshape to list of pixels
        pixels = filtered_image.reshape(-1, 3)

        # Remove black pixels (which were green carpet)
        non_black_pixels = pixels[~np.all(pixels == [0, 0, 0], axis=1)]

        # If too few pixels remain, use original image
        pixels_to_use = non_black_pixels if len(non_black_pixels) > 1000 else pixels

        # Apply KMeans clustering
        kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)
        kmeans.fit(pixels_to_use)

        # Get colors and their counts
        colors = kmeans.cluster_centers_.astype(int)
        labels = kmeans.labels_
        counts = Counter(labels)

        # Sort colors by frequency
        sorted_indices = [i for i, _ in counts.most_common()]
        sorted_colors = [tuple(colors[i]) for i in sorted_indices]

        # Filter out near-black colors (these may be artifacts)
        filtered_colors = []
        for color in sorted_colors:
            r, g, b = color
            # If not very dark, eliminates clusters that are very dark (usually noise).
            if r + g + b > 30:
                filtered_colors.append(color)

        # If all colors were filtered, return original sorted colors
        if not filtered_colors:
            filtered_colors = sorted_colors

        # Pad with black if needed
        while len(filtered_colors) < n_colors:
            filtered_colors.append((0, 0, 0))

        return filtered_colors[:n_colors]

    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return [(0, 0, 0)] * n_colors


def get_dominant_colors(image_path, n_colors=N_COLORS, method="extcolors"):
    """Extract dominant colors using the specified method"""
    if method == "extcolors":
        return get_colors_with_extcolors(image_path, n_colors)
    # Directly call get_colors_with_kmeans() if not using extcolors method
    return get_colors_with_kmeans(image_path, n_colors)

"""**Squared Euclidean Distance**

---



The distance calculation uses the squared Euclidean distance formula in three-dimensional RGB space, which measures how "far apart" two colors are mathematically. While more sophisticated color matching algorithms exist that better match human visual perception (like CIEDE2000 which operates in LAB color space), the RGB Euclidean approach offers an excellent balance of accuracy and computational efficiency for most applications.

This function implements a color matching algorithm that takes any RGB color value and finds its closest named equivalent in the CSS3 color standard. It works by:

1. Accepting an RGB tuple input (values from 0-255 for each channel)
2. Computing the mathematical "distance" between the input color and every named color in the CSS3 palette
3. Identifying the color with the smallest distance, which represents the closest visual match

While there are more perceptually accurate color distance metrics like CIEDE2000,Euclidean distance provides a good balance of accuracy and computational efficiency for this application.
"""

# Function to map RGB values to color names
# This is essential for converting numerical RGB values into human-readable
# Color names that users can understand

def closest_color(rgb_tuple):
    """
    Find the closest color name for an RGB value using the CSS3 color database.

    """
    # Convert RGB tuple to a comparable format
    r, g, b = rgb_tuple

    # Calculate color difference using Euclidean distance
    min_distance = float('inf')
    closest_name = "Unknown"

    for name, color_rgb in CSS3_COLORS.items():
        # Calculate distance between colors
        distance = (
            (r - color_rgb[0]) ** 2 +
            (g - color_rgb[1]) ** 2 +
            (b - color_rgb[2]) ** 2
        ) ** 0.5

        if distance < min_distance:
            min_distance = distance
            closest_name = name

    return closest_name

def display_color_palette(colors):
    """Display a horizontal color palette"""

    height = 50
    width = 100
    palette = np.zeros((height, width * len(colors), 3), dtype=np.uint8)

    for i, color in enumerate(colors):
        palette[:, i*width:(i+1)*width] = color

    plt.figure(figsize=(10, 2))
    plt.imshow(palette)
    plt.axis('off')

    # Add color names
    for i, color in enumerate(colors):
        color_name = closest_color(color)
        plt.text(i*width + width//2, height + 5, color_name,
                horizontalalignment='center',
                color='black')

    plt.tight_layout()
    plt.show()

def analyze_all_images(method="extcolors"):
    """Process all images and create dataset"""
    print(f"Analyzing images using {method} method...")

    if not os.path.exists(IMAGE_FOLDER):
        print(f"Error: Folder {IMAGE_FOLDER} not found")
        return pd.DataFrame()

    image_files = [f for f in os.listdir(IMAGE_FOLDER)
                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    if not image_files:
        print(f"No image files found in {IMAGE_FOLDER}")
        return pd.DataFrame()

    print(f"Processing {len(image_files)} images...")

    data = []
    for img_name in image_files:
        path = os.path.join(IMAGE_FOLDER, img_name)

        # Extract celebrity name from filename
        celebrity_name = os.path.splitext(img_name)[0].replace('_', ' ').title()

        # Get dominant colors
        dom_colors = get_dominant_colors(path, method=method)
        color_names = [closest_color(tuple(c)) for c in dom_colors]

        # Calculate percentages (simplified)
        percentages = [100 // len(dom_colors)] * len(dom_colors)

        data.append({
            'image': img_name,
            'celebrity': celebrity_name,
            'dominant_color': color_names[0] if color_names else "unknown",
            'palette': ', '.join(color_names),
            'color_percentages': str(percentages),
            'rgb_values': str([tuple(c) for c in dom_colors])
        })

    df = pd.DataFrame(data)

    # Save to CSV
    if len(df) > 0:
        df.to_csv(OUTPUT_CSV, index=False)
        print(f"Data saved to {OUTPUT_CSV}")

    return df

def plot_color_distribution(df):
    """Visualize color distribution"""
    plt.figure(figsize=(12, 8))

    # Use actual colors for the bars
    color_counts = df['dominant_color'].value_counts()

    # Get RGB values for each color name
    bar_colors = [CSS3_COLORS.get(color, (128, 128, 128)) for color in color_counts.index]
    bar_colors = [(r/255, g/255, b/255) for r, g, b in bar_colors]

    # Create bar plot
    ax = sns.barplot(x=color_counts.values, y=color_counts.index, palette=bar_colors)

    plt.title('Most Popular Outfit Colors at Met Gala 2024', fontsize=16)
    plt.xlabel('Number of Celebrities', fontsize=12)
    plt.ylabel('Color', fontsize=12)

    # Force x-axis to show only integers
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))

    # Add count labels to bars
    for i, v in enumerate(color_counts.values):
        ax.text(v + 0.1, i, str(v), va='center')

    plt.tight_layout()
    plt.show()

def find_celebrity(df, name):
    """Find and analyze a specific celebrity"""
    # Case-insensitive partial matching
    matches = df[df['celebrity'].str.lower().str.contains(name.lower())]

    if len(matches) == 0:
        print(f"Uh-oh, {name} not on Anna Wintour's guest list!")
        return

    celebrity = matches.iloc[0]
    print(f"\n{celebrity['celebrity']}'s outfit colors:")
    print(f"All colors: {celebrity['palette']}")

    # Display image and color palette
    img_path = os.path.join(IMAGE_FOLDER, celebrity['image'])
    colors_rgb = eval(celebrity['rgb_values'])

    try:
        # Read and display image
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            plt.figure(figsize=(14, 6))

            # Show original image
            plt.subplot(1, 2, 1)
            plt.imshow(img)
            plt.title(celebrity['celebrity'])
            plt.axis('off')

            # Show color palette
            plt.subplot(1, 2, 2)
            height = 100
            width = 100
            palette = np.zeros((height, width * len(colors_rgb), 3), dtype=np.uint8)

            for i, color in enumerate(colors_rgb):
                palette[:, i*width:(i+1)*width] = color

                # Add color name
                color_name = closest_color(color)
                plt.text(i*width + width//2, height//2, color_name,
                        horizontalalignment='center',
                        verticalalignment='center',
                        color='white' if sum(color) < 380 else 'black',
                        fontweight='bold')

            plt.imshow(palette)
            plt.title('Outfit Colors')
            plt.axis('off')
            plt.tight_layout()
            plt.show()

    except Exception as e:
        print(f"Error displaying image: {e}")
        # Just show the color palette
        display_color_palette(colors_rgb)

def main():
    print("Welcome to Met Gala 2024 Color Analysis!")
    print("----------------------------------------")
    # Set the method used for color detection
    method = "extcolors"

    # Check if color data was already saved before
    if os.path.exists(OUTPUT_CSV):
        print(f"Found existing data in {OUTPUT_CSV}, loading it now...")
        df = pd.read_csv(OUTPUT_CSV)
    else:
        print("No saved data found. Analyzing all images in the folder...")
        df = analyze_all_images(method=method)

    # If no data is available, stop the program
    if df.empty:
        print("No data to work with. Make sure your image folder is not empty.")
        return

    # Show overall color trends
    plot_color_distribution(df)

    # Let user search for specific celebrities
    while True:
        name = input("\nEnter a celebrity name to analyze (or type 'exit' to quit): ").strip()
        if name.lower() == 'exit':
            print("Goodbye!")
            break
        try:
            plt.close('all')  # Clear any old charts
            find_celebrity(df, name)
        except Exception as e:
            print(f"Oops! Something went wrong: {e}. Please try again.")

if __name__ == "__main__":
    main()

"""**Challenges Faced**

---


While adapting a flag color analysis method to fashion imagery, several unique challenges emerged. One major hurdle was the presence of the carpet itself in many Met Gala images, which often skewed the color extraction by introducing dominant shades of green and beige that didn’t belong to the outfits. I had to implement pre-processing steps, to minimize background influence and isolate the actual clothing.

Another challenge stemmed from the way extcolors works—it returns the closest named colors, but not the exact hex values or nuanced shades found in high-fashion garments. As a result, subtle fabric details like gradients, metallics, or sheer overlays often got reduced to flat, generalized color labels. This limitation made it harder to capture the full complexity and richness of couture design.

Additionally, the color extraction and visualization process could be time-consuming, especially when handling multiple high-resolution images. User input—such as uploading new images or requesting custom color clustering—required noticeable processing time, depending on image size and system memory. While acceptable for a small batch, the current workflow may not scale efficiently without optimization.



**Future Improvements**

---


Future iterations of this project could benefit from more refined image segmentation techniques—perhaps integrating machine learning-based object detection to automatically separate outfits from the background. Additionally, using a custom color clustering approach with perceptual color distance metrics (like CIEDE2000) could yield more accurate results than relying on standard named colors. Finally, developing an interactive visualization layer to compare designers, celebrities, or themes by color palette over the years could make this a valuable archival and trend-spotting tool for fashion historians and enthusiasts alike.

**Materials & Resources**

---


1. Flags Colors Project by Geodev
Geodev. 2023. “Flags Colors.” Geodev Projects. Accessed May 10, 2025. https://www.geodev.me/projects.
2. Python Colour Info Extractor by Kynlos
Kynlos. 2025. “Python-Colour-Info-Extractor.” GitHub. Accessed May 10, 2025. https://github.com/Kynlos/Python-Colour-Info-Extractor.
3. extcolors
CairX. 2022. extcolors 1.0.2. Python Package Index. Accessed May 10, 2025. https://pypi.org/project/extcolors/.
4. scikit-learn KMeans
Pedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “sklearn.cluster.KMeans.” Scikit-learn Documentation. Accessed May 10, 2025. https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html.
5. matplotlib ticker API
Hunter, John D., and Michael Droettboom et al. 2024. “matplotlib.ticker — Matplotlib Ticker API.” Matplotlib Documentation. Accessed May 10, 2025. https://matplotlib.org/stable/api/ticker_api.html.
6. Pillow Image Module
Clark, Alex et al. 2024. “Image Module.” Pillow (PIL Fork) Documentation. Accessed May 10, 2025. https://pillow.readthedocs.io/en/stable/reference/Image.html.
7. Medium article on image color extraction
Zhao, Yin. 2019. “Image Color Extraction with Python in 4 Steps.” Medium. February 19, 2019. https://medium.com/data-science/image-color-extraction-with-python-in-4-steps-8d9370d9216e.
8. Comparing Two Images
Nicholls, Rowan. 2021. “Comparing Two Images.” Rowan Nicholls Blog. Accessed May 10, 2025. https://rowannicholls.github.io/python/image_analysis/comparing_two_images.html.
9. GeeksforGeeks – Euclidean Distance with NumPy
GeeksforGeeks. 2021. “Calculate the Euclidean Distance Using NumPy.” GeeksforGeeks. June 4, 2021. https://www.geeksforgeeks.org/calculate-the-euclidean-distance-using-numpy/.
10. Baeldung. 2023. “How to Compute the Similarity of Colours.” Baeldung. Accessed May 10, 2025. https://www.baeldung.com/cs/compute-similarity-of-colours.
11. Reddy, Tejesh. 2020. “Difference Between 2 Colours Using Python.” DEV Community. September 12, 2020. Accessed May 10, 2025. https://dev.to/tejeshreddy/color-difference-between-2-colours-using-python-182b.
"""